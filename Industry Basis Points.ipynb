{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "from pynse import *\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "#import mplfinance as mpf\n",
    "import time, asyncio\n",
    "import matplotlib.dates as mdates\n",
    "import mplfinance as mpf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "import scipy.stats as stats\n",
    "from tvDatafeed import TvDatafeed,Interval\n",
    "tv=TvDatafeed()\n",
    "\n",
    "\n",
    "nse=Nse()\n",
    "#nse.bhavcopy(series=\"all\")\n",
    "#bhavcopy_full=nse.bhavcopy(series=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING RAW DATA AND SAVING PROCESSED CSV's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for PE and MCAP\n",
    "folder_path = \"C:/Users/99111/OneDrive/Desktop/Full data set/Price, PE, EBITDA , EV & Mcap/*.csv\"\n",
    "\n",
    "files = glob.glob(folder_path)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "PEMCAP = pd.concat(df_list)\n",
    "PEMCAP = PEMCAP.rename(columns={'NDP_Date': 'Date'})\n",
    "PEMCAP['Date'] = pd.to_datetime(PEMCAP['Date'])\n",
    "Sectors = PEMCAP['CD_Sector'].unique().tolist()\n",
    "Industrys = PEMCAP['CD_Industry'].unique().tolist()\n",
    "PEMCAP = PEMCAP.loc[:, ['CD_NSE Symbol', 'CD_Sector' , 'CD_Industry', 'Date', 'NDP_Mcap', 'NDP_Consolidated PE', 'NDP_Consolidated EV EBIDTA']].copy()\n",
    "PEMCAP['uniquecode'] = PEMCAP['CD_NSE Symbol'] + PEMCAP['Date'].astype(str)\n",
    "\n",
    "#Price and symbol data\n",
    "folder_path = \"C:/Users/99111/OneDrive/Documents/pynse/Shashank work/data/raw/Delivdata/*.csv\"\n",
    "\n",
    "files = glob.glob(folder_path)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df = df.rename(columns={'DATE1': 'Date'})\n",
    "\n",
    "\n",
    "df['Open'] = np.where(df['OPEN_PRICE'] > 0, df['OPEN_PRICE'], df['OPEN'])\n",
    "df['High'] = np.where(df['HIGH_PRICE'] > 0, df['HIGH_PRICE'], df['HIGH'])\n",
    "df['Low'] = np.where(df['LOW_PRICE'] > 0, df['LOW_PRICE'], df['LOW'])\n",
    "df['Close'] = np.where(df['CLOSE_PRICE'] > 0, df['CLOSE_PRICE'], df['CLOSE'])\n",
    "df['Prevclose'] = np.where(df['PREV_CLOSE'] > 0, df['PREV_CLOSE'], df['PREVCLOSE']) \n",
    "\n",
    "df['TradedQuantity'] = np.where(df['TTL_TRD_QNTY'] > 0, df['TTL_TRD_QNTY'], df['TOTTRDQTY'])\n",
    "df['Numberoftrades'] = np.where(df['NO_OF_TRADES'] > 0, df['NO_OF_TRADES'], df['TOTALTRADES'])\n",
    "df['Averageprice'] = np.where(df['AVG_PRICE'] > 0, df['AVG_PRICE'], (df['Open']+df['High']+df['Low']+df['Close']+df['Prevclose'])/5)\n",
    "\n",
    "df['TURNOVER_LACS'] = df['TURNOVER_LACS'] / 100\n",
    "df['TOTTRDVAL'] = df['TOTTRDVAL'] / 10000000\n",
    "df['Turnover_CR'] = np.where(df['TURNOVER_LACS'] > 0, df['TURNOVER_LACS'], df['TOTTRDVAL'])\n",
    "df = df.loc[:, ['SYMBOL','Date', 'Prevclose', 'Open', 'High', 'Low', 'Close','Averageprice', 'TradedQuantity', 'Numberoftrades', 'Turnover_CR', 'DELIV_QTY', 'DELIV_PER']]\n",
    "df['uniquecode'] = df['SYMBOL'] + df['Date'].astype(str)\n",
    "df = df.sort_values(by='Date', ascending=True)\n",
    "\n",
    "#Combining data\n",
    "df1 = pd.merge(df, PEMCAP, on='uniquecode', how='left')\n",
    "df1.drop_duplicates(subset='uniquecode', keep='first', inplace=True)\n",
    "df1['Date_x'] = pd.to_datetime(df1['Date_x'])\n",
    "df1 = df1.loc[:, ['SYMBOL','Date_x', 'Prevclose', 'Open', 'High', 'Low', 'Close', 'Averageprice', 'TradedQuantity', 'Numberoftrades', 'Turnover_CR', 'DELIV_QTY', 'CD_Sector', 'CD_Industry', 'NDP_Mcap', 'NDP_Consolidated PE', 'NDP_Consolidated EV EBIDTA']]\n",
    "\n",
    "#Cutting of data data lenght\n",
    "datacutoffdate = pd.to_datetime('2010-1-1')\n",
    "df1 = df1[df1['Date_x'] >= datacutoffdate]\n",
    "\n",
    "#creating symbols list \n",
    "symbolcutoffdate = pd.to_datetime('2023-7-20')\n",
    "symdf = df1[df1['Date_x'] >= symbolcutoffdate]\n",
    "symbols = symdf['SYMBOL'].unique().tolist()\n",
    "df1 = df1[df1['SYMBOL'].isin(symbols)]\n",
    "\n",
    "######################\n",
    "\n",
    "#file_path = r'C:\\Users\\99111\\OneDrive\\Desktop\\Stocklist.xlsx'\n",
    "#symbols = pd.read_excel(file_path)\n",
    "#symbols = symbols['Symbol_NIFTY100'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CSV's of the raw data and the symbols selected are based on the 2 sets of code block right abpve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        df2=df1[(df1['SYMBOL'] == symbol)].copy()\n",
    "\n",
    "        df2 = df2.sort_values(by='Date_x', ascending=True)\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "\n",
    "        cols_to_fill_forward = ['CD_Sector', 'CD_Industry', 'NDP_Mcap', 'NDP_Consolidated PE', 'NDP_Consolidated EV EBIDTA']\n",
    "        df2[cols_to_fill_forward] = df2[cols_to_fill_forward].fillna(method='ffill')\n",
    "\n",
    "        #fields for Industry analysis\n",
    "        df2['Return_3days'] = ((df2['NDP_Mcap'] - df2['NDP_Mcap'].shift(3)) / df2['NDP_Mcap'].shift(3)) * 100\n",
    "        df2['Return_5days'] = ((df2['NDP_Mcap'] - df2['NDP_Mcap'].shift(5)) / df2['NDP_Mcap'].shift(5)) * 100\n",
    "\n",
    "        df2['TurnoverCR_3daysAVG'] = df2['Turnover_CR'].rolling(3).mean()\n",
    "        df2['TO_Weighted_3dayreturns'] = df2['TurnoverCR_3daysAVG'] * df2['Return_3days']\n",
    "        df2['MCAP_Weighted_3dayreturns'] = df2['NDP_Mcap'] * df2['Return_3days']\n",
    "\n",
    "        df2['TurnoverCR_5daysAVG'] = df2['Turnover_CR'].rolling(5).mean()\n",
    "        df2['TO_Weighted_5dayreturns'] = df2['TurnoverCR_5daysAVG'] * df2['Return_5days']\n",
    "        df2['MCAP_Weighted_5dayreturns'] = df2['NDP_Mcap'] * df2['Return_5days']\n",
    "\n",
    "        for N in [63, 126, 252, 504]:\n",
    "            weighting_factors = [i / sum(range(1, N + 1)) for i in range(1, N + 1)]\n",
    "            df2[f'TWClose_{N}'] = df2['NDP_Mcap'].rolling(window=N, min_periods=N).apply(lambda x: (x * weighting_factors).sum())\n",
    "    \n",
    "\n",
    "        df2['Price>TW63'] = (df2['NDP_Mcap'] > df2['TWClose_63']).astype(int)\n",
    "        df2['Price>TW126'] = (df2['NDP_Mcap'] > df2['TWClose_126']).astype(int)\n",
    "        df2['Price>TW252'] = (df2['NDP_Mcap'] > df2['TWClose_252']).astype(int)\n",
    "        df2['Price>TW504'] = (df2['NDP_Mcap'] > df2['TWClose_504']).astype(int)\n",
    "\n",
    "        output_directory = r'C:\\Users\\99111\\OneDrive\\Desktop\\daily updates\\MarketBreath and StageAnalysis\\Data\\IndustryData'\n",
    "        output_filename = f'{symbol}.csv'\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        df2.to_csv(output_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "                print(f\"Error while processing outer forloop {symbol}: {e}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/99111/OneDrive/Desktop/daily updates/MarketBreath and StageAnalysis/Data/IndustryData/*.csv\"\n",
    "\n",
    "files = glob.glob(folder_path)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "Sectors = df['CD_Sector'].unique().tolist()\n",
    "df['Price>TW63'] = df['Price>TW63'].astype(int)\n",
    "df['Price>TW126'] = df['Price>TW126'].astype(int)\n",
    "df['Price>TW252'] = df['Price>TW252'].astype(int)\n",
    "df['Price>TW504'] = df['Price>TW504'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defensive and Expantionary Mcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_industries = [\n",
    "    'Pharmaceuticals & Drugs', 'Healthcare Services', 'Hospital & Healthcare Services', 'Power Generation/Distribution',\n",
    "    'Gas Transmission/Marketing', 'Edible Oil', 'Telecommunication - Service Provider', 'Consumer Food',\n",
    "    'Telecommunication - Equipment', 'Household & Personal Products', 'Tobacco/Cigarettes', 'Utilities',\n",
    "    'Food and Beverage', 'Non-Cyclical Consumer Goods'\n",
    "]\n",
    "\n",
    "df['defnondef'] = df['CD_Industry'].apply(lambda industry: 'Defensive' if industry in defensive_industries else 'NonDefensive')\n",
    "DefnonDefs = df['defnondef'].unique().tolist()\n",
    "\n",
    "\n",
    "df1 = df[df['defnondef'] == 'NonDefensive']\n",
    "df1 = df1.sort_values(by='Date_x', ascending=True)\n",
    "df1['Count'] = 1\n",
    "selected_columns = ['TurnoverCR_3daysAVG', 'NDP_Mcap', 'TO_Weighted_3dayreturns', 'MCAP_Weighted_3dayreturns', 'Count', 'Price>TW63', 'Price>TW126', 'Price>TW252', 'Price>TW504']\n",
    "grouped_df1 = df1.groupby('Date_x')[selected_columns].sum().reset_index()\n",
    "\n",
    "df2 = df[df['defnondef'] == 'Defensive']\n",
    "df2 = df2.sort_values(by='Date_x', ascending=True)\n",
    "df2['Count'] = 1\n",
    "selected_columns = ['TurnoverCR_3daysAVG', 'NDP_Mcap', 'TO_Weighted_3dayreturns', 'MCAP_Weighted_3dayreturns', 'Count', 'Price>TW63', 'Price>TW126', 'Price>TW252', 'Price>TW504']\n",
    "grouped_df2 = df2.groupby('Date_x')[selected_columns].sum().reset_index()\n",
    "\n",
    "grouped_df1['Date_x'] = pd.to_datetime(grouped_df1['Date_x'])\n",
    "grouped_df2['Date_x'] = pd.to_datetime(grouped_df2['Date_x'])\n",
    "\n",
    "\n",
    "date = pd.to_datetime('2012-7-1')\n",
    "grouped_df1 = grouped_df1[grouped_df1['Date_x'] >= date]\n",
    "grouped_df2 = grouped_df2[grouped_df2['Date_x'] >= date]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        \n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Def')\n",
    "ax1.plot(grouped_df1['Date_x'], grouped_df1['NDP_Mcap'], label='Expansionary', color = 'black')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        \n",
    "#ax2.set_ylabel(DefnonDef)  # we already handled the x-label with ax1\n",
    "ax2.plot(grouped_df2['Date_x'], grouped_df2['NDP_Mcap'], label='Defensive')\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_dir = r'C:\\Users\\99111\\OneDrive\\Desktop\\daily updates\\MarketBreath and StageAnalysis'        \n",
    "chart_file = os.path.join(save_dir, \"Expansive and Defensive.jpg\")\n",
    "plt.savefig(chart_file, dpi=100)\n",
    "\n",
    "# Close the figure to release resources\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketwide and Industries Market breath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_x'] = pd.to_datetime(df['Date_x'])\n",
    "df = df.sort_values(by='Date_x', ascending=True)\n",
    "df['Count'] = 1\n",
    "selected_columns = ['TurnoverCR_3daysAVG', 'NDP_Mcap', 'TO_Weighted_3dayreturns', 'MCAP_Weighted_3dayreturns', 'Count', 'Price>TW63', 'Price>TW126', 'Price>TW252', 'Price>TW504']\n",
    "grouped_df = df.groupby('Date_x')[selected_columns].sum().reset_index()\n",
    "grouped_df['McapWeightedReturn'] = grouped_df['MCAP_Weighted_3dayreturns'] / grouped_df['NDP_Mcap']\n",
    "grouped_df['TOWeightedReturn'] = grouped_df['TO_Weighted_3dayreturns'] / grouped_df['TurnoverCR_3daysAVG']\n",
    "\n",
    "grouped_df['Over63'] = (grouped_df['Price>TW63'] / grouped_df['Count']) * 100\n",
    "grouped_df['Over126'] = (grouped_df['Price>TW126'] / grouped_df['Count']) * 100\n",
    "grouped_df['Over252'] = (grouped_df['Price>TW252'] / grouped_df['Count']) * 100\n",
    "grouped_df['Over504'] = (grouped_df['Price>TW504'] / grouped_df['Count']) * 100\n",
    "\n",
    "grouped_df['63-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW504']\n",
    "grouped_df['126-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW252']\n",
    "\n",
    "\n",
    "grouped_df['Date_x'] = pd.to_datetime(grouped_df['Date_x'])\n",
    "\n",
    "date = pd.to_datetime('2020-7-1')\n",
    "Marketwide = grouped_df[grouped_df['Date_x'] >= date]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "# Create the first subplot for columns A and B\n",
    "axs[0].plot(Marketwide['Date_x'],Marketwide['Over63'], label='Over63')\n",
    "axs[0].plot(Marketwide['Date_x'],Marketwide['Over252'], label='Over252')\n",
    "axs[0].plot(Marketwide['Date_x'],Marketwide['Over504'], label='Over504')\n",
    "axs[0].legend()\n",
    "axs[0].axhline(35, color='black')\n",
    "axs[0].axhline(60, color='black')\n",
    "axs[0].set_title('MarketWide')\n",
    "axs[0].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "   \n",
    "ax2 = axs[1].twinx()\n",
    "axs[1].plot(Marketwide['Date_x'],Marketwide['63-504'], label='63-504', color='green')\n",
    "axs[1].plot(Marketwide['Date_x'],Marketwide['126-504'], label='126-504', color='red')\n",
    "axs[1].axhline(0, color='black')\n",
    "# Format x-axis date ticks for the second subplot\n",
    "axs[1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "#ax2.plot(grouped_df1['CE.totalSellQuantity'], label='call SQ', color='red')\n",
    "#ax2.plot(grouped_df1['PE.totalSellQuantity'], label='Put SQ', color='green')\n",
    "\n",
    "# Set labels and titles for both y-axes\n",
    "axs[1].set_ylabel('Call TSQ / Put TSQ')\n",
    "\n",
    "# Combine the legends from both axes\n",
    "lines, labels = axs[1].get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "axs[1].legend(lines + lines2, labels + labels2)\n",
    "\n",
    "axs[1].set_title('MarketWide')\n",
    "\n",
    "# Adjust the spacing to avoid overlapping labels\n",
    "fig.tight_layout()\n",
    "save_dir = r'C:\\Users\\99111\\OneDrive\\Desktop\\daily updates\\MarketBreath and StageAnalysis\\Industry Charts'        \n",
    "chart_file = os.path.join(save_dir, f\"{'MarketWide'}.jpg\")\n",
    "plt.savefig(chart_file, dpi=100)\n",
    "\n",
    "# Close the figure to release resources\n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "for sector in Sectors:\n",
    "    try:\n",
    "           \n",
    "        df1 = df[df['CD_Sector'] == sector]\n",
    "        df1 = df1.sort_values(by='Date_x', ascending=True)\n",
    "        df1['Count'] = 1\n",
    "        selected_columns = ['TurnoverCR_3daysAVG', 'NDP_Mcap', 'TO_Weighted_3dayreturns', 'MCAP_Weighted_3dayreturns', 'Count', 'Price>TW63', 'Price>TW126', 'Price>TW252', 'Price>TW504']\n",
    "        grouped_df = df1.groupby('Date_x')[selected_columns].sum().reset_index()\n",
    "        grouped_df['McapWeightedReturn'] = grouped_df['MCAP_Weighted_3dayreturns'] / grouped_df['NDP_Mcap']\n",
    "        grouped_df['TOWeightedReturn'] = grouped_df['TO_Weighted_3dayreturns'] / grouped_df['TurnoverCR_3daysAVG']\n",
    "\n",
    "        grouped_df['Over63'] = (grouped_df['Price>TW63'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over126'] = (grouped_df['Price>TW126'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over252'] = (grouped_df['Price>TW252'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over504'] = (grouped_df['Price>TW504'] / grouped_df['Count']) * 100\n",
    "\n",
    "        grouped_df['63-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW504']\n",
    "        grouped_df['126-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW252']\n",
    "\n",
    "        grouped_df['Date_x'] = pd.to_datetime(grouped_df['Date_x'])\n",
    "\n",
    "        #date = pd.to_datetime('2020-7-1')\n",
    "        grouped_df1 = grouped_df[grouped_df['Date_x'] >= date]\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(30, 15))\n",
    "        # Create the first subplot for columns A and B\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over63'], label='Over63')\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over252'], label='Over252')\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over504'], label='Over504')\n",
    "        axs[0].plot(Marketwide['Date_x'],Marketwide['Over252'], label='Over252', color='black', linestyle='--')\n",
    "        axs[0].legend()\n",
    "        axs[0].axhline(35, color='black')\n",
    "        axs[0].axhline(60, color='black')\n",
    "        axs[0].set_title(sector)\n",
    "        # Format x-axis date ticks\n",
    "        axs[0].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "                \n",
    "        ax2 = axs[1].twinx()\n",
    "        axs[1].plot(grouped_df1['Date_x'],grouped_df1['63-504'], label='63-504', color='green')\n",
    "        axs[1].plot(grouped_df1['Date_x'],grouped_df1['126-504'], label='126-504', color='red')\n",
    "        #axs[1].plot(Marketwide['Date_x'],Marketwide['126-504'], label='126-504', color='red')\n",
    "        axs[1].axhline(0, color='black')\n",
    "        # Format x-axis date ticks for the second subplot\n",
    "        axs[1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        #ax2.plot(grouped_df1['CE.totalSellQuantity'], label='call SQ', color='red')\n",
    "        #ax2.plot(grouped_df1['PE.totalSellQuantity'], label='Put SQ', color='green')\n",
    "\n",
    "        # Set labels and titles for both y-axes\n",
    "        axs[1].set_ylabel('Call TSQ / Put TSQ')\n",
    "\n",
    "        # Combine the legends from both axes\n",
    "        lines, labels = axs[1].get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        axs[1].legend(lines + lines2, labels + labels2)\n",
    "\n",
    "        axs[1].set_title(sector)\n",
    "\n",
    "        # Adjust the spacing to avoid overlapping labels\n",
    "        fig.tight_layout()\n",
    "        save_dir = r'C:\\Users\\99111\\OneDrive\\Desktop\\daily updates\\MarketBreath and StageAnalysis\\Industry Charts'        \n",
    "        chart_file = os.path.join(save_dir, f\"{sector}.jpg\")\n",
    "        plt.savefig(chart_file, dpi=100)\n",
    "\n",
    "        # Close the figure to release resources\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "                print(f\"Error while processing outer forloop {sector}: {e}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expansionary and Defensive Market breath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for sector in DefnonDefs:\n",
    "    try:\n",
    "           \n",
    "        df1 = df[df['defnondef'] == sector]\n",
    "        df1 = df1.sort_values(by='Date_x', ascending=True)\n",
    "        df1['Count'] = 1\n",
    "        selected_columns = ['TurnoverCR_3daysAVG', 'NDP_Mcap', 'TO_Weighted_3dayreturns', 'MCAP_Weighted_3dayreturns', 'Count', 'Price>TW63', 'Price>TW126', 'Price>TW252', 'Price>TW504']\n",
    "        grouped_df = df1.groupby('Date_x')[selected_columns].sum().reset_index()\n",
    "        grouped_df['McapWeightedReturn'] = grouped_df['MCAP_Weighted_3dayreturns'] / grouped_df['NDP_Mcap']\n",
    "        grouped_df['TOWeightedReturn'] = grouped_df['TO_Weighted_3dayreturns'] / grouped_df['TurnoverCR_3daysAVG']\n",
    "\n",
    "        grouped_df['Over63'] = (grouped_df['Price>TW63'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over126'] = (grouped_df['Price>TW126'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over252'] = (grouped_df['Price>TW252'] / grouped_df['Count']) * 100\n",
    "        grouped_df['Over504'] = (grouped_df['Price>TW504'] / grouped_df['Count']) * 100\n",
    "\n",
    "        grouped_df['63-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW504']\n",
    "        grouped_df['126-504'] = grouped_df['Price>TW63'] - grouped_df['Price>TW252']\n",
    "\n",
    "        grouped_df['Date_x'] = pd.to_datetime(grouped_df['Date_x'])\n",
    "\n",
    "        #date = pd.to_datetime('2020-7-1')\n",
    "        grouped_df1 = grouped_df[grouped_df['Date_x'] >= date]\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(30, 15))\n",
    "        # Create the first subplot for columns A and B\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over63'], label='Over63')\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over252'], label='Over252')\n",
    "        axs[0].plot(grouped_df1['Date_x'],grouped_df1['Over504'], label='Over504')\n",
    "        axs[0].plot(Marketwide['Date_x'],Marketwide['Over252'], label='Over252', color='black', linestyle='--')\n",
    "        axs[0].legend()\n",
    "        axs[0].axhline(35, color='black')\n",
    "        axs[0].axhline(60, color='black')\n",
    "        axs[0].set_title(sector)\n",
    "        # Format x-axis date ticks\n",
    "        axs[0].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "                \n",
    "        ax2 = axs[1].twinx()\n",
    "        axs[1].plot(grouped_df1['Date_x'],grouped_df1['63-504'], label='63-504', color='green')\n",
    "        axs[1].plot(grouped_df1['Date_x'],grouped_df1['126-504'], label='126-504', color='red')\n",
    "        #axs[1].plot(Marketwide['Date_x'],Marketwide['126-504'], label='126-504', color='red')\n",
    "        axs[1].axhline(0, color='black')\n",
    "        # Format x-axis date ticks for the second subplot\n",
    "        axs[1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "        axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        #ax2.plot(grouped_df1['CE.totalSellQuantity'], label='call SQ', color='red')\n",
    "        #ax2.plot(grouped_df1['PE.totalSellQuantity'], label='Put SQ', color='green')\n",
    "\n",
    "        # Set labels and titles for both y-axes\n",
    "        axs[1].set_ylabel('Call TSQ / Put TSQ')\n",
    "\n",
    "        # Combine the legends from both axes\n",
    "        lines, labels = axs[1].get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        axs[1].legend(lines + lines2, labels + labels2)\n",
    "\n",
    "        axs[1].set_title(sector)\n",
    "\n",
    "        # Adjust the spacing to avoid overlapping labels\n",
    "        fig.tight_layout()\n",
    "        save_dir = r'C:\\Users\\99111\\OneDrive\\Desktop\\daily updates\\MarketBreath and StageAnalysis'        \n",
    "        chart_file = os.path.join(save_dir, f\"{sector}.jpg\")\n",
    "        plt.savefig(chart_file, dpi=100)\n",
    "\n",
    "        # Close the figure to release resources\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "                print(f\"Error while processing outer forloop {sector}: {e}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27156bc63d14a65dfa14e1b73b9a41f3aeb50270a4e898aa5ea771669f0a0420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
